{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üîç Pipeline Overview\n",
        "Parse logs: Read log data (e.g., from a .log or .csv file).\n",
        "\n",
        "* Extract relevant fields: Timestamp, IP, message, severity, etc.\n",
        "\n",
        "* Define threat rules: Based on IP repetition, error types, login failures, etc.\n",
        "\n",
        "* Detect anomalies: Using heuristics or ML (if needed).\n",
        "\n",
        "* Summarize findings: Show suspicious IPs, timestamps, messages."
      ],
      "metadata": {
        "id": "EUstZIHH3FnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "92eV5x2yrMHL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sample python code to analyze the security log reports for below threat rules:\n",
        "\n",
        "\n",
        "*   Multiple failed login attempts from same IP in a short time.\n",
        "*   Access to restricted endpoints\n",
        "*   Known vulnerability patterns in request URLs."
      ],
      "metadata": {
        "id": "ZarS1zZP2Wro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Sample log format: 2025-07-10 14:23:01,IP:192.168.1.5,EVENT:Failed login for user 'admin'\n",
        "LOG_PATTERN = r\"(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}),IP:(?P<ip>[\\d\\.]+),EVENT:(?P<event>.+)\"\n",
        "\n",
        "def parse_logs(log_file_path):\n",
        "    logs = []\n",
        "    with open(log_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            match = re.match(LOG_PATTERN, line.strip())\n",
        "            if match:\n",
        "                logs.append(match.groupdict())\n",
        "    return pd.DataFrame(logs)\n",
        "\n",
        "def preprocess_logs(df):\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    return df\n",
        "\n",
        "def detect_failed_logins(df, threshold=5, window_minutes=5):\n",
        "    threats = []\n",
        "    df_failed = df[df['event'].str.contains(\"Failed login\", case=False)]\n",
        "    grouped = df_failed.groupby('ip')\n",
        "    for ip, group in grouped:\n",
        "        group = group.sort_values('timestamp')\n",
        "        for i in range(len(group) - threshold + 1):\n",
        "            if group.iloc[i + threshold - 1]['timestamp'] - group.iloc[i]['timestamp'] <= timedelta(minutes=window_minutes):\n",
        "                threats.append({\n",
        "                    'ip': ip,\n",
        "                    'threat_type': 'Brute-force login',\n",
        "                    'start_time': group.iloc[i]['timestamp'],\n",
        "                    'end_time': group.iloc[i + threshold - 1]['timestamp'],\n",
        "                    'attempts': threshold\n",
        "                })\n",
        "                break\n",
        "    return threats\n",
        "\n",
        "def detect_restricted_access(df):\n",
        "    threats = []\n",
        "    restricted_patterns = [\"admin\", \"config\", \"passwd\", \".env\"]\n",
        "    for _, row in df.iterrows():\n",
        "        if any(pat in row['event'].lower() for pat in restricted_patterns):\n",
        "            threats.append({\n",
        "                'ip': row['ip'],\n",
        "                'threat_type': 'Restricted area access attempt',\n",
        "                'timestamp': row['timestamp'],\n",
        "                'event': row['event']\n",
        "            })\n",
        "    return threats\n",
        "\n",
        "def analyze_logs(file_path):\n",
        "    df = parse_logs(file_path)\n",
        "    df = preprocess_logs(df)\n",
        "    brute_force_threats = detect_failed_logins(df)\n",
        "    restricted_access_threats = detect_restricted_access(df)\n",
        "    return brute_force_threats + restricted_access_threats\n",
        "\n",
        "\n",
        "threat_report = analyze_logs(\"/content/sample_data/security_logs.txt\")\n",
        "for threat in threat_report:\n",
        "  print(threat)\n"
      ],
      "metadata": {
        "id": "tCyxDep-3Yfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fa3544-e190-48ef-aafb-9b65dbf7301f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ip': '192.168.1.5', 'threat_type': 'Brute-force login', 'start_time': Timestamp('2025-07-10 14:23:01'), 'end_time': Timestamp('2025-07-10 14:24:01'), 'attempts': 5}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:23:01'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:23:15'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:23:30'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:23:45'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:24:01'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.9', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 15:01:01'), 'event': 'Accessed /admin/settings'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîß **Extended Plan: Add Anomaly Detection\n",
        "We'll:**\n",
        "\n",
        "* Convert IPs to numerical values.\n",
        "\n",
        "* Extract features from log events (event type counts, time of access).\n",
        "\n",
        "* Fit an Isolation Forest to detect abnormal patterns."
      ],
      "metadata": {
        "id": "a2STkapV3CmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import socket\n",
        "import struct\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "\n",
        "LOG_PATTERN = r\"(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}),IP:(?P<ip>[\\d\\.]+),EVENT:(?P<event>.+)\"\n",
        "\n",
        "def parse_logs(log_file_path):\n",
        "    logs = []\n",
        "    with open(log_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            match = re.match(LOG_PATTERN, line.strip())\n",
        "            if match:\n",
        "                logs.append(match.groupdict())\n",
        "    return pd.DataFrame(logs)\n",
        "\n",
        "def preprocess_logs(df):\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['event_lower'] = df['event'].str.lower()\n",
        "    df['event_len'] = df['event'].str.len()\n",
        "    df['ip_num'] = df['ip'].apply(ip_to_int)\n",
        "    return df\n",
        "\n",
        "def ip_to_int(ip):\n",
        "    try:\n",
        "        return struct.unpack(\"!I\", socket.inet_aton(ip))[0]\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def detect_failed_logins(df, threshold=5, window_minutes=5):\n",
        "    threats = []\n",
        "    df_failed = df[df['event_lower'].str.contains(\"failed login\")]\n",
        "    grouped = df_failed.groupby('ip')\n",
        "    for ip, group in grouped:\n",
        "        group = group.sort_values('timestamp')\n",
        "        for i in range(len(group) - threshold + 1):\n",
        "            if group.iloc[i + threshold - 1]['timestamp'] - group.iloc[i]['timestamp'] <= timedelta(minutes=window_minutes):\n",
        "                threats.append({\n",
        "                    'ip': ip,\n",
        "                    'threat_type': 'Brute-force login',\n",
        "                    'start_time': group.iloc[i]['timestamp'],\n",
        "                    'end_time': group.iloc[i + threshold - 1]['timestamp'],\n",
        "                    'attempts': threshold\n",
        "                })\n",
        "                break\n",
        "    return threats\n",
        "\n",
        "def detect_restricted_access(df):\n",
        "    threats = []\n",
        "    restricted_patterns = [\"admin\", \"config\", \"passwd\", \".env\"]\n",
        "    for _, row in df.iterrows():\n",
        "        if any(pat in row['event_lower'] for pat in restricted_patterns):\n",
        "            threats.append({\n",
        "                'ip': row['ip'],\n",
        "                'threat_type': 'Restricted area access attempt',\n",
        "                'timestamp': row['timestamp'],\n",
        "                'event': row['event']\n",
        "            })\n",
        "    return threats\n",
        "\n",
        "def extract_features_for_ml(df):\n",
        "    df_grouped = df.groupby('ip').agg({\n",
        "        'event_len': 'mean',\n",
        "        'hour': 'median',\n",
        "        'ip_num': 'first',\n",
        "        'event_lower': lambda x: sum(['failed' in e for e in x])  # Count of \"failed\" in events\n",
        "    }).rename(columns={'event_lower': 'failed_count'})\n",
        "    return df_grouped.reset_index()\n",
        "\n",
        "def detect_anomalies(df_features):\n",
        "    model = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
        "    df_features['anomaly'] = model.fit_predict(df_features[['event_len', 'hour', 'ip_num', 'failed_count']])\n",
        "    anomalies = df_features[df_features['anomaly'] == -1]\n",
        "    return anomalies[['ip', 'event_len', 'hour', 'failed_count']]\n",
        "\n",
        "def analyze_logs_with_ml(file_path):\n",
        "    df = parse_logs(file_path)\n",
        "    df = preprocess_logs(df)\n",
        "\n",
        "    brute_force_threats = detect_failed_logins(df)\n",
        "    restricted_access_threats = detect_restricted_access(df)\n",
        "\n",
        "    features = extract_features_for_ml(df)\n",
        "    anomaly_ips = detect_anomalies(features)\n",
        "\n",
        "    anomaly_threats = [{\n",
        "        'ip': row['ip'],\n",
        "        'threat_type': 'Anomalous behavior detected by ML',\n",
        "        'details': {\n",
        "            'mean_event_length': row['event_len'],\n",
        "            'median_hour': row['hour'],\n",
        "            'failed_login_events': row['failed_count']\n",
        "        }\n",
        "    } for _, row in anomaly_ips.iterrows()]\n",
        "\n",
        "    return brute_force_threats + restricted_access_threats + anomaly_threats\n",
        "\n",
        "# Example usage\n",
        "threat_report = analyze_logs_with_ml(\"/content/sample_data/security_logs.txt\")\n",
        "for threat in threat_report:\n",
        "    print(threat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBaaUZtD50kf",
        "outputId": "7695de3d-432e-4f98-fe2e-553edd068f30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ip': '192.168.1.5', 'threat_type': 'Brute-force login', 'start_time': Timestamp('2025-07-10 14:23:01'), 'end_time': Timestamp('2025-07-10 14:24:01'), 'attempts': 5}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:23:01'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:23:15'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:23:30'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:23:45'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.5', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 14:24:01'), 'event': \"Failed login for user 'admin'\"}\n",
            "{'ip': '192.168.1.9', 'threat_type': 'Restricted area access attempt', 'timestamp': Timestamp('2025-07-10 15:01:01'), 'event': 'Accessed /admin/settings'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M-TLYF3608L",
        "outputId": "44051eb0-0670-42b2-9363-6eb5b14157d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.45.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import re\n",
        "import socket\n",
        "import struct\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "\n",
        "LOG_PATTERN = r\"(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}),IP:(?P<ip>[\\d\\.]+),EVENT:(?P<event>.+)\"\n",
        "\n",
        "def parse_logs(log_file_path):\n",
        "    logs = []\n",
        "    with open(log_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            match = re.match(LOG_PATTERN, line.strip())\n",
        "            if match:\n",
        "                logs.append(match.groupdict())\n",
        "    return pd.DataFrame(logs)\n",
        "\n",
        "def preprocess_logs(df):\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['event_lower'] = df['event'].str.lower()\n",
        "    df['event_len'] = df['event'].str.len()\n",
        "    df['ip_num'] = df['ip'].apply(ip_to_int)\n",
        "    return df\n",
        "\n",
        "def ip_to_int(ip):\n",
        "    try:\n",
        "        return struct.unpack(\"!I\", socket.inet_aton(ip))[0]\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def detect_failed_logins(df, threshold=5, window_minutes=5):\n",
        "    threats = []\n",
        "    df_failed = df[df['event_lower'].str.contains(\"failed login\")]\n",
        "    grouped = df_failed.groupby('ip')\n",
        "    for ip, group in grouped:\n",
        "        group = group.sort_values('timestamp')\n",
        "        for i in range(len(group) - threshold + 1):\n",
        "            if group.iloc[i + threshold - 1]['timestamp'] - group.iloc[i]['timestamp'] <= timedelta(minutes=window_minutes):\n",
        "                threats.append({\n",
        "                    'ip': ip,\n",
        "                    'threat_type': 'Brute-force login',\n",
        "                    'start_time': group.iloc[i]['timestamp'],\n",
        "                    'end_time': group.iloc[i + threshold - 1]['timestamp'],\n",
        "                    'attempts': threshold\n",
        "                })\n",
        "                break\n",
        "    return threats\n",
        "\n",
        "def detect_restricted_access(df):\n",
        "    threats = []\n",
        "    restricted_patterns = [\"admin\", \"config\", \"passwd\", \".env\"]\n",
        "    for _, row in df.iterrows():\n",
        "        if any(pat in row['event_lower'] for pat in restricted_patterns):\n",
        "            threats.append({\n",
        "                'ip': row['ip'],\n",
        "                'threat_type': 'Restricted area access attempt',\n",
        "                'timestamp': row['timestamp'],\n",
        "                'event': row['event']\n",
        "            })\n",
        "    return threats\n",
        "\n",
        "def extract_features_for_ml(df):\n",
        "    df_grouped = df.groupby('ip').agg({\n",
        "        'event_len': 'mean',\n",
        "        'hour': 'median',\n",
        "        'ip_num': 'first',\n",
        "        'event_lower': lambda x: sum(['failed' in e for e in x])  # Count of \"failed\" in events\n",
        "    }).rename(columns={'event_lower': 'failed_count'})\n",
        "    return df_grouped.reset_index()\n",
        "\n",
        "def detect_anomalies(df_features):\n",
        "    model = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
        "    df_features['anomaly'] = model.fit_predict(df_features[['event_len', 'hour', 'ip_num', 'failed_count']])\n",
        "    anomalies = df_features[df_features['anomaly'] == -1]\n",
        "    return anomalies[['ip', 'event_len', 'hour', 'failed_count']]\n",
        "\n",
        "def analyze_logs_with_ml(file_path):\n",
        "    df = parse_logs(file_path)\n",
        "    df = preprocess_logs(df)\n",
        "\n",
        "    brute_force_threats = detect_failed_logins(df)\n",
        "    restricted_access_threats = detect_restricted_access(df)\n",
        "\n",
        "    features = extract_features_for_ml(df)\n",
        "    anomaly_ips = detect_anomalies(features)\n",
        "\n",
        "    anomaly_threats = [{\n",
        "        'ip': row['ip'],\n",
        "        'threat_type': 'Anomalous behavior detected by ML',\n",
        "        'details': {\n",
        "            'mean_event_length': row['event_len'],\n",
        "            'median_hour': row['hour'],\n",
        "            'failed_login_events': row['failed_count']\n",
        "        }\n",
        "    } for _, row in anomaly_ips.iterrows()]\n",
        "\n",
        "    return brute_force_threats + restricted_access_threats + anomaly_threats\n",
        "\n",
        "# Upload and parse logs\n",
        "st.title(\"üîí Security Log Threat Analyzer\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload your log file (.txt)\", type=[\"txt\"])\n",
        "if uploaded_file:\n",
        "    # Save uploaded file temporarily\n",
        "    with open(\"temp_logs.txt\", \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    # Analyze logs\n",
        "    with st.spinner(\"Analyzing logs...\"):\n",
        "        threats = analyze_logs_with_ml(\"temp_logs.txt\")\n",
        "\n",
        "    # Convert threats to DataFrame\n",
        "    df_threats = pd.DataFrame(threats)\n",
        "\n",
        "    st.success(f\"Detected {len(df_threats)} potential threats\")\n",
        "    st.dataframe(df_threats)\n",
        "\n",
        "    # Filter controls\n",
        "    unique_types = df_threats['threat_type'].unique()\n",
        "    selected_types = st.multiselect(\"Filter by threat type\", unique_types, default=unique_types)\n",
        "\n",
        "    filtered_df = df_threats[df_threats['threat_type'].isin(selected_types)]\n",
        "\n",
        "    # Visualize\n",
        "    st.subheader(\"üìä Threat Summary\")\n",
        "    st.bar_chart(filtered_df['threat_type'].value_counts())\n",
        "\n",
        "    if 'details' in df_threats.columns:\n",
        "        df_details = df_threats.dropna(subset=['details']).copy()\n",
        "        df_details = df_details[df_details['details'].notnull()]\n",
        "        if not df_details.empty:\n",
        "            st.subheader(\"üìà ML-Based Anomaly Insights\")\n",
        "            details_expanded = df_details['details'].apply(pd.Series)\n",
        "            st.line_chart(details_expanded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIjFWsNs6-vB",
        "outputId": "9852e9f2-c2b4-4743-81ed-dfca1cb4c2da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-11 06:08:28.401 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 06:08:28.615 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-07-11 06:08:28.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 06:08:28.622 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 06:08:28.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 06:08:28.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 06:08:28.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 06:08:28.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 06:08:28.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-11 06:08:28.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# prompt: run the above streamlit app\n",
        "\n",
        "!streamlit run /content/sample_data/main.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkuZti0a7tIX",
        "outputId": "49671b27-7403-4645-a4be-7cbdcb1db1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.150.227.64:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0Kyour url is: https://lemon-goats-hang.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Threat Analysis Recommendations Report\n",
        "1. Strengthen Authentication Mechanisms\n",
        "- Enforce strong password policies\n",
        "- Implement multi-factor authentication (MFA)\n",
        "- Lock accounts after failed login attempts\n",
        "- Use CAPTCHA to block brute-force bots\n",
        "2. Harden Access to Sensitive Endpoints\n",
        "- Restrict access to /admin, /config, etc.\n",
        "- Move admin panels behind VPN/IP whitelist\n",
        "- Rename admin paths and secure .env files\n",
        "- Disable directory listings\n",
        "3. Block or Check Reputation of Suspicious IPs\n",
        "- Use Geo-blocking\n",
        "- Integrate threat intelligence feeds\n",
        "- Automatically block repeat offenders\n",
        "4. Improve Monitoring and Alerting\n",
        "- Use SIEM tools (ELK, Splunk)\n",
        "- Set real-time alerts for anomalies and failures\n",
        "- Integrate Slack/email notifications\n",
        "5. Enhance Logging Practices\n",
        "- Log user agents, paths, session data\n",
        "- Implement secure, append-only logging\n",
        "- Apply log rotation and retention policies\n",
        "6. Leverage ML More Deeply\n",
        "- Train models on historical logs\n",
        "- Use time-series for slow attacks\n",
        "- Apply clustering to uncover new threat patterns\n",
        "7. Automate Threat Response\n",
        "- Integrate with WAF/Security groups\n",
        "- Automate actions using SOAR platforms\n",
        "- Create response playbooks for common threats"
      ],
      "metadata": {
        "id": "h5U4WOlFFUWg"
      }
    }
  ]
}